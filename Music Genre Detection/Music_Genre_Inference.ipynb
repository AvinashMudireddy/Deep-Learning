{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Genre_Inference.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference for Model Testing"
      ],
      "metadata": {
        "id": "VIUtDHPhr3AT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### INSTRUCTIONS"
      ],
      "metadata": {
        "id": "LGgHPZTxr6fS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "rRJrt8s9uRP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Install all required libraries.\n",
        "2. Download weights for pre-trained model to extract feature representations of audio files\n",
        "3. Load weights for rnn_epoch_100_R2 model provided.\n",
        "4. Load all .npy files. This is required to map the prdicted genre id to a genre class as defined in the other notebook.\n",
        "5. Ensure the flask_app folder provided in the zip folder is avaialble on your google drive. \n",
        "6. Sign up for ngrok and provide authentication code below.\n",
        "7. Run python app.py.\n",
        "8. You can provide the flask app with either a .WAV file or a youtube link as input.\n",
        "9. Youtube link takes a few minutes to first download the song and then conducts inference."
      ],
      "metadata": {
        "id": "fOKWd8l9r9tF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken #add token"
      ],
      "metadata": {
        "id": "RrX19K8tuYFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2waJhFhWKR4U",
        "outputId": "b0c7d5cf-ae6d-46d3-8a16-5717240b367a"
      },
      "source": [
        "!pip install mirdata\n",
        "!pip install essentia-tensorflow\n",
        "!pip install youtube_dl\n",
        "!pip install pydub"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mirdata\n",
            "  Downloading mirdata-0.3.6-py3-none-any.whl (13.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.1 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from mirdata) (1.19.5)\n",
            "Collecting jams\n",
            "  Downloading jams-0.3.4.tar.gz (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 72 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mirdata) (4.62.3)\n",
            "Requirement already satisfied: librosa>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from mirdata) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from mirdata) (2.23.0)\n",
            "Collecting pretty-midi>=0.2.8\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 29.2 MB/s \n",
            "\u001b[?25hCollecting Deprecated>=1.2.13\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from mirdata) (3.0.4)\n",
            "Requirement already satisfied: h5py>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from mirdata) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from mirdata) (5.2.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mirdata) (3.13)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from mirdata) (1.4.1)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated>=1.2.13->mirdata) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.10.0->mirdata) (1.5.2)\n",
            "Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (0.51.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (1.1.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (4.4.2)\n",
            "Requirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (0.10.3.post1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (1.5.2)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (0.2.2)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (1.0.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (21.3)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa>=0.8.0->mirdata) (2.1.9)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->mirdata) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa>=0.8.0->mirdata) (57.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa>=0.8.0->mirdata) (3.0.6)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa>=0.8.0->mirdata) (1.4.4)\n",
            "Collecting mido>=1.1.16\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[K     |████████████████████████████████| 51 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pretty-midi>=0.2.8->mirdata) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa>=0.8.0->mirdata) (3.0.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa>=0.8.0->mirdata) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa>=0.8.0->mirdata) (2.21)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from jams->mirdata) (1.1.5)\n",
            "Requirement already satisfied: sortedcontainers>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from jams->mirdata) (2.4.0)\n",
            "Collecting jsonschema>=3.0.0\n",
            "  Downloading jsonschema-4.2.1-py3-none-any.whl (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.5 MB/s \n",
            "\u001b[?25hCollecting mir_eval>=0.5\n",
            "  Downloading mir_eval-0.6.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 6.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (21.2.0)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (5.4.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (0.18.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=3.0.0->jams->mirdata) (4.8.2)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=3.0.0->jams->mirdata) (3.6.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from mir_eval>=0.5->jams->mirdata) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema>=3.0.0->jams->mirdata) (3.10.0.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->jams->mirdata) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->jams->mirdata) (2.8.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->mirdata) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->mirdata) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->mirdata) (2021.10.8)\n",
            "Building wheels for collected packages: pretty-midi, jams, mir-eval\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591953 sha256=17c4407c870d20fc469d09d617d2abea11a1b2da0e05521b7f710dd0fa7f643e\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/74/7c/a06473ca8dcb63efb98c1e67667ce39d52100f837835ea18fa\n",
            "  Building wheel for jams (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jams: filename=jams-0.3.4-py3-none-any.whl size=64924 sha256=611f61c8964a45cb79c4addc88ad6b9ff3d8a5e284f19666d4636c82f175fd68\n",
            "  Stored in directory: /root/.cache/pip/wheels/c9/aa/16/ce72bc4caa58dfab819e3f46b3542f2bf90a83009f4ea07a48\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.6-py3-none-any.whl size=96514 sha256=faeaef64a433805d8b29213e368aef3fedf136fe7094051521ccafb681362b32\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/28/2d/006dbad29550bac8daf049ff34fa882655a7d3e77f3b67595e\n",
            "Successfully built pretty-midi jams mir-eval\n",
            "Installing collected packages: mir-eval, mido, jsonschema, pretty-midi, jams, Deprecated, mirdata\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 2.6.0\n",
            "    Uninstalling jsonschema-2.6.0:\n",
            "      Successfully uninstalled jsonschema-2.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "nbclient 0.5.9 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 jams-0.3.4 jsonschema-4.2.1 mido-1.2.10 mir-eval-0.6 mirdata-0.3.6 pretty-midi-0.2.9\n",
            "Collecting essentia-tensorflow\n",
            "  Downloading essentia_tensorflow-2.1b6.dev609-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (291.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 291.4 MB 5.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from essentia-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from essentia-tensorflow) (3.13)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from essentia-tensorflow) (1.19.5)\n",
            "Installing collected packages: essentia-tensorflow\n",
            "Successfully installed essentia-tensorflow-2.1b6.dev609\n",
            "Collecting youtube_dl\n",
            "  Downloading youtube_dl-2021.6.6-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 4.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: youtube-dl\n",
            "Successfully installed youtube-dl-2021.6.6\n",
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "VBisJNoGqCgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "import torchaudio\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torchaudio.datasets import GTZAN\n",
        "from torchaudio.datasets.utils import download_url\n",
        "from torch.utils.data import DataLoader\n",
        "import torchaudio.transforms as tt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable"
      ],
      "metadata": {
        "id": "wSzcl528poRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18BMoE3fKuSf"
      },
      "source": [
        "import os\n",
        "from youtube_dl import YoutubeDL\n",
        "import IPython\n",
        "from pydub import AudioSegment\n",
        "\n",
        "audio_downloder = YoutubeDL({'format':'bestaudio'})"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnsPW3wXKsfn"
      },
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "\n",
        "\n",
        "import essentia.standard as es\n",
        "import mirdata\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "\n",
        "from collections import Counter\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEw3_5ptKSjQ",
        "outputId": "6ec3f2e0-962c-4961-cd3e-aaabf229ab1c"
      },
      "source": [
        "!curl -SLO https://essentia.upf.edu/models/classifiers/genre_tzanetakis/genre_tzanetakis-musicnn-msd-1.json\n",
        "!curl -SLO https://essentia.upf.edu/models/classifiers/genre_tzanetakis/genre_tzanetakis-musicnn-msd-1.pb\n",
        "\n",
        "MODEL_NAME = 'genre_tzanetakis-musicnn-msd-1'\n",
        "MODEL_JSON = f'{MODEL_NAME}.json'\n",
        "MODEL_PB = f'{MODEL_NAME}.pb'\n",
        "\n",
        "musicnn_metadata = json.load(open(MODEL_JSON, 'r'))\n",
        "for k, v in musicnn_metadata.items():\n",
        "    print('{}: {}'.format(k , v))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2092  100  2092    0     0    835      0  0:00:02  0:00:02 --:--:--   835\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 3166k  100 3166k    0     0   331k      0  0:00:09  0:00:09 --:--:--  289k\n",
            "name: genre GTZAN\n",
            "type: multi-class classifier\n",
            "link: https://essentia.upf.edu/models/classifiers/genre_tzanetakis/genre_tzanetakis-musicnn-msd-1.pb\n",
            "version: 1\n",
            "description: classification of music by genre\n",
            "author: Pablo Alonso\n",
            "email: pablo.alonso@upf.edu\n",
            "release_date: 2020-03-31\n",
            "framework: tensorflow\n",
            "framework_version: 1.15.0\n",
            "classes: ['blu', 'cla', 'cou', 'dis', 'hip', 'jaz', 'met', 'pop', 'reg', 'roc']\n",
            "model_types: ['frozen_model']\n",
            "dataset: {'name': 'the GTZAN Genre Collection', 'citation': '@article{tzanetakis2002musical,\\n  title={Musical genre classification of audio signals},\\n  author={Tzanetakis, George and Cook, Perry},\\n  journal={IEEE Transactions on speech and audio processing},\\n  volume={10},\\n  number={5},\\n  pages={293--302},\\n  year={2002},\\n  publisher={IEEE}\\n}', 'size': '1000 track excerpts, 100 per genre', 'metrics': {'5-fold_cross_validation_normalized_accuracy': 0.83}}\n",
            "schema: {'inputs': [{'name': 'model/Placeholder', 'type': 'float', 'shape': [187, 96]}], 'outputs': [{'name': 'model/Sigmoid', 'type': 'float', 'shape': [1, 10], 'op': 'Sigmoid'}, {'name': 'model/dense_2/BiasAdd', 'type': 'float', 'shape': [1, 10], 'op': 'fully connected', 'description': 'logits'}, {'name': 'model/dense_1/BiasAdd', 'type': 'float', 'shape': [1, 100], 'op': 'fully connected', 'description': 'penultimate layer'}, {'name': 'model/dense/BiasAdd', 'type': 'float', 'shape': [1, 200], 'op': 'fully connected', 'description': 'embeddings'}]}\n",
            "citation: @article{alonso2020tensorflow,\n",
            "title={TensorFlow Audio Models in Essentia},\n",
            "author={Alonso-Jim{\\'e}nez, Pablo and Bogdanov, Dmitry and Pons, Jordi and Serra, Xavier},\n",
            "journal={ICASSP 2020},\n",
            "year={2020}\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fr3g0zr8KXtq"
      },
      "source": [
        "MUSICNN_SR = 16000 #We will fix sample rate at 16 kHz as it is required for the input of MusiCNN model.\n",
        "def extract_mean_embedding(filename):\n",
        "  \"\"\"\n",
        "  Extract mean-temporal embedding from audio contained in filename\n",
        "\n",
        "  Args:\n",
        "    filename (str): Name of the audio file\n",
        "\n",
        "  Return:\n",
        "    Mean embedding of the song\n",
        "  \"\"\"\n",
        "  \n",
        "  # Load audiofile with essentia monoloader to resample the audios to the necessary sample rate in MusiCNN model\n",
        "  audio = es.MonoLoader(filename=filename, sampleRate=MUSICNN_SR)()\n",
        "\n",
        "  # Extract the embedding\n",
        "  musicnn_emb = es.TensorflowPredictMusiCNN(graphFilename=MODEL_PB, output='model/dense/BiasAdd')(audio)\n",
        "\n",
        "  # Compute mean-embedding across the frames\n",
        "  mean_emb = np.mean(musicnn_emb, axis=0)\n",
        "  mean_emb = mean_emb[np.newaxis, :]  # Each song is a 1x200 row vector\n",
        "\n",
        "  return mean_emb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gPEmzbuKjCA"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(RNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.hidden_size = hidden_size\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=0.4)\n",
        "        self.fc1 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(0)\n",
        "        # print(\"Input Shape\",x.shape)\n",
        "        h0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).float())\n",
        "        c0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size).float())\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out) \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE-742VNDoWk"
      },
      "source": [
        "model = torch.load('/content/rnn_epoch_100_R2',map_location=torch.device('cpu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_KETCJ3J18L"
      },
      "source": [
        "with open('/content/embeddings.npy', 'rb') as f:\n",
        "    embeddings = np.load(f)\n",
        "with open('/content/labels.npy', 'rb') as f:\n",
        "    labels = np.load(f)\n",
        "with open('/content/labels_decoded.npy', 'rb') as f:\n",
        "    labels_decoded = np.load(f)\n",
        "with open('/content/track_ids.npy', 'rb') as f:\n",
        "    track_ids = np.load(f)\n",
        "\n",
        "genres = {genre_id: genre for genre_id, genre in zip(labels, labels_decoded)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAV81gmSJ5pt"
      },
      "source": [
        "def get_genre(wav_file=None,youtube_link=None):\n",
        "  if youtube_link:\n",
        "    info = audio_downloder.extract_info(url=youtube_link, download=True)\n",
        "    wav = AudioSegment.from_file(info['title']+'-'+info['display_id']+'.'+info['ext'])\n",
        "    wav.export(\"temp.wav\", format=\"wav\")\n",
        "    features = extract_mean_embedding(\"temp.wav\")\n",
        "    os.remove(\"temp.wav\")\n",
        "  else:\n",
        "    features = extract_mean_embedding(wav_file)\n",
        "\n",
        "  feature_tensor = torch.from_numpy(features)\n",
        "  outputs = model(feature_tensor).squeeze(0)\n",
        "  _, predicted = torch.max(outputs, 1)\n",
        "  print(genres[predicted.item()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1IQoQ8zL6CJ",
        "outputId": "cedf27e0-a43e-4641-98dc-e6b66fa70be1"
      },
      "source": [
        "get_genre(youtube_link=\"https://www.youtube.com/watch?v=qyYmS_iBcy4\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] qyYmS_iBcy4: Downloading webpage\n",
            "[download] Destination: LORNA SHORE - To the Hellfire (OFFICIAL VIDEO)-qyYmS_iBcy4.m4a\n",
            "[download] 100% of 5.64MiB in 01:12\n",
            "[ffmpeg] Correcting container in \"LORNA SHORE - To the Hellfire (OFFICIAL VIDEO)-qyYmS_iBcy4.m4a\"\n",
            "metal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2R0ybG28G7w"
      },
      "source": [
        "### Flask Application"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6DM4gTi8-Vq",
        "outputId": "627691fa-8220-4668-8ff4-0aaa0c452438"
      },
      "source": [
        "cd /content/gdrive/MyDrive/machine-learning-deployment/flask_app"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/machine-learning-deployment/predict sales\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctZcOVPF9H2h",
        "outputId": "9d81b420-46f5-4f76-d170-509ed66ea30c"
      },
      "source": [
        "!python app.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-12-05 22:10:16.181069: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[0;32m[   INFO   ] \u001b[0mMusicExtractorSVM: no classifier models were configured by default\n",
            "2021-12-05 22:10:16.901406: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-12-05 22:10:16.903151: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-05 22:10:16.916527: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-12-05 22:10:16.916600: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (abf72cc8d9ad): /proc/driver/nvidia/version does not exist\n",
            " * Serving Flask app \"app\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: on\n",
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
            " * Restarting with stat\n",
            "2021-12-05 22:10:21.606867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[0;32m[   INFO   ] \u001b[0mMusicExtractorSVM: no classifier models were configured by default\n",
            "2021-12-05 22:10:22.361813: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2021-12-05 22:10:22.364351: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-12-05 22:10:22.381856: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2021-12-05 22:10:22.381934: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (abf72cc8d9ad): /proc/driver/nvidia/version does not exist\n",
            " * Debugger is active!\n",
            " * Debugger PIN: 323-023-100\n",
            "127.0.0.1 - - [05/Dec/2021 22:10:25] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n"
          ]
        }
      ]
    }
  ]
}